{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0efc12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T17:01:25.774118Z",
     "start_time": "2022-09-21T17:01:18.986712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snscrape\n",
      "  Downloading snscrape-0.4.3.20220106-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from snscrape) (2021.1)\n",
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (from snscrape) (4.6.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from snscrape) (4.9.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from snscrape) (3.0.12)\n",
      "Requirement already satisfied: requests[socks] in c:\\programdata\\anaconda3\\lib\\site-packages (from snscrape) (2.25.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape) (2.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Installing collected packages: snscrape\n",
      "Successfully installed snscrape-0.4.3.20220106\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6120588a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T21:11:15.734038Z",
     "start_time": "2022-09-22T21:11:13.739109Z"
    }
   },
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33420026",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T21:11:18.011474Z",
     "start_time": "2022-09-22T21:11:17.994519Z"
    }
   },
   "outputs": [],
   "source": [
    "#query='GoDaddy'\n",
    "#query=(\"(from:elonmusk) until:2020-01-01 since:2010-01-01\")\n",
    "#query=(\"(from:GoDaddy) until:2022-09-21 since:2010-01-01\")\n",
    "query=(\"GoDaddy until:2022-09-22 since:2010-01-01\")\n",
    "tweets=[]\n",
    "limit=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a11044a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T21:14:41.733625Z",
     "start_time": "2022-09-22T21:14:40.662479Z"
    }
   },
   "outputs": [],
   "source": [
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    #print(vars(tweet))\n",
    "    #break\n",
    "    if len(tweets)==limit:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([tweet.date,tweet.user,tweet])\n",
    "\n",
    "df=pd.DataFrame(tweets, columns=['Date','User','Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c24673",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T21:14:42.462516Z",
     "start_time": "2022-09-22T21:14:42.434588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-21 23:59:27+00:00</td>\n",
       "      <td>DNSocialNetwork</td>\n",
       "      <td>https://twitter.com/DNSocialNetwork/status/157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-21 23:56:49+00:00</td>\n",
       "      <td>sinabagci</td>\n",
       "      <td>https://twitter.com/sinabagci/status/157273664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-21 23:56:09+00:00</td>\n",
       "      <td>Adverrdomains</td>\n",
       "      <td>https://twitter.com/Adverrdomains/status/15727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-21 23:55:52+00:00</td>\n",
       "      <td>Adverrdomains</td>\n",
       "      <td>https://twitter.com/Adverrdomains/status/15727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-21 23:55:46+00:00</td>\n",
       "      <td>Adverrdomains</td>\n",
       "      <td>https://twitter.com/Adverrdomains/status/15727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-09-21 23:45:18+00:00</td>\n",
       "      <td>MediaReaders</td>\n",
       "      <td>https://twitter.com/MediaReaders/status/157273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-09-21 23:42:13+00:00</td>\n",
       "      <td>Foone</td>\n",
       "      <td>https://twitter.com/Foone/status/1572732965633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-09-21 23:00:16+00:00</td>\n",
       "      <td>Goddessgowns1</td>\n",
       "      <td>https://twitter.com/Goddessgowns1/status/15727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-09-21 23:00:05+00:00</td>\n",
       "      <td>dnprotect</td>\n",
       "      <td>https://twitter.com/dnprotect/status/157272235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-09-21 22:41:54+00:00</td>\n",
       "      <td>digitalcandyuk</td>\n",
       "      <td>https://twitter.com/digitalcandyuk/status/1572...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date             User  \\\n",
       "0 2022-09-21 23:59:27+00:00  DNSocialNetwork   \n",
       "1 2022-09-21 23:56:49+00:00        sinabagci   \n",
       "2 2022-09-21 23:56:09+00:00    Adverrdomains   \n",
       "3 2022-09-21 23:55:52+00:00    Adverrdomains   \n",
       "4 2022-09-21 23:55:46+00:00    Adverrdomains   \n",
       "5 2022-09-21 23:45:18+00:00     MediaReaders   \n",
       "6 2022-09-21 23:42:13+00:00            Foone   \n",
       "7 2022-09-21 23:00:16+00:00    Goddessgowns1   \n",
       "8 2022-09-21 23:00:05+00:00        dnprotect   \n",
       "9 2022-09-21 22:41:54+00:00   digitalcandyuk   \n",
       "\n",
       "                                               Tweet  \n",
       "0  https://twitter.com/DNSocialNetwork/status/157...  \n",
       "1  https://twitter.com/sinabagci/status/157273664...  \n",
       "2  https://twitter.com/Adverrdomains/status/15727...  \n",
       "3  https://twitter.com/Adverrdomains/status/15727...  \n",
       "4  https://twitter.com/Adverrdomains/status/15727...  \n",
       "5  https://twitter.com/MediaReaders/status/157273...  \n",
       "6  https://twitter.com/Foone/status/1572732965633...  \n",
       "7  https://twitter.com/Goddessgowns1/status/15727...  \n",
       "8  https://twitter.com/dnprotect/status/157272235...  \n",
       "9  https://twitter.com/digitalcandyuk/status/1572...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad48ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.028283Z",
     "start_time": "2022-09-22T16:24:52.386Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698c4fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.032273Z",
     "start_time": "2022-09-22T16:24:52.416Z"
    }
   },
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274d5b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.034268Z",
     "start_time": "2022-09-22T16:24:52.448Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7a1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.038256Z",
     "start_time": "2022-09-22T16:24:52.483Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('GoDaddy 20000 Twitter tweets from 4-9-2019 to 20-9-2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8c2c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.040251Z",
     "start_time": "2022-09-22T16:24:52.511Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('GoDaddy 20000 Twitter tweets from 4-9-2019 to 20-9-2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e4334",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.043244Z",
     "start_time": "2022-09-22T16:24:52.539Z"
    }
   },
   "outputs": [],
   "source": [
    "#5000 tweets of Account:elonmusk from 2010 to 2020\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6e071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.045238Z",
     "start_time": "2022-09-22T16:24:52.569Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4585e951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.047232Z",
     "start_time": "2022-09-22T16:24:52.596Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370dc11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e6c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3383647d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.051222Z",
     "start_time": "2022-09-22T16:24:52.685Z"
    }
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295997e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.053216Z",
     "start_time": "2022-09-22T16:24:52.715Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ea167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T16:24:53.056209Z",
     "start_time": "2022-09-22T16:24:52.746Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "#Scipy is used to convert the output of the model to probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "769a41c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T20:54:01.386334Z",
     "start_time": "2022-09-21T20:54:01.381344Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bed0a86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T20:38:39.270309Z",
     "start_time": "2022-09-21T20:38:39.261334Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet = \"@MehranShakarami today's cold @ home 😒 https://mehranshakarami.com\"\n",
    "#tweet = 'Great content! subscribed 😉'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67e2ad8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T20:43:29.405600Z",
     "start_time": "2022-09-21T20:43:29.383658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@user today's cold @ home 😒 http\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precprcess tweet\n",
    "tweet_words = []\n",
    "\n",
    "for word in tweet.split(' '):\n",
    "    if word.startswith('@') and len(word) > 1:\n",
    "        word = '@user'\n",
    "    \n",
    "    elif word.startswith('http'):\n",
    "        word = \"http\"\n",
    "    tweet_words.append(word)\n",
    "\n",
    "tweet_proc = \" \".join(tweet_words)\n",
    "\n",
    "tweet_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3b3872b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T21:04:42.607037Z",
     "start_time": "2022-09-21T21:04:30.326418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe9ae241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T21:07:28.063624Z",
     "start_time": "2022-09-21T21:07:28.039691Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-65b20190b8db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mroberta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"cardiffnlp/twitter-roberta-base-sentiment\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroberta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroberta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m    945\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         \u001b[0mrequires_backends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backends\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;31m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"torch\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"tf\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPYTORCH_IMPORT_ERROR_WITH_TF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;31m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a7267ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-21T20:55:07.504665Z",
     "start_time": "2022-09-21T20:55:07.478698Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-578e9ea0555e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# sentiment analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencoded_tweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_proc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mencoded_tweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# sentiment analysis\n",
    "encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
    "# output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\n",
    "output = model(**encoded_tweet)\n",
    "\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e846f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(scores)):\n",
    "    \n",
    "    l = labels[i]\n",
    "    s = scores[i]\n",
    "    print(l,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ce199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce98079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd4829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175319ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79d125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
